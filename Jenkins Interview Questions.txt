1) Explain the Devops process from develpment to release?

First of all, there is two weeks sprint, sprint planning and sprint review meetings, in that we will take various kinds of inputs like will have backlog management	which will comes from the various team members. We will have the pipelines which will be actually
triggering a web hook like web hook will be triggered when there is commit on the github by developers which will intern trigger pipeline job which consists of various stages inside the groovy script and also talking to various stakeholders in the integrating
the various testing tools with the application pipelines then apart from that was also responsible for doing some of the deployment orchestration and I was the one who was releasing the code to the target server.

validate - validate the project is correct and all necessary information is available
compile - compile the source code of the project
test - test the compiled source code using a suitable unit testing framework. These tests should not require the code be packaged or deployed
package - take the compiled code and package it in its distributable format, such as a JAR.
verify - run any checks on results of integration tests to ensure quality criteria are met
install - install the package into the local repository, for use as a dependency in other projects locally
deploy - done in the build environment, copies the final package to the remote repository for sharing with other developers and projects.


2) Can you please explain the one of yours jenkins file and what it is doing?

We have created one pipeline was to deploy the java application. INitially started with the application is being commited by the developers in the code repository. in that, we have git flow branching strategy, now if we talk about branching and merging strategy,
we have used the git flow for various branches included but not limited to release branch, develop branch, bugfix branch as well apart from that we have environment specific branches, any old legacy branches etc.. now developer check in to the develop branch,
once its done development will trigger a webhook in the jenkins which will intern trigger a pipeline job, we have various steps in the pipeline job..


1) checkout SCM - checkout the code using git develop branch into jenkins server
2) run a static code analysis of java code, lot of times developer will not takecare of having the empty cache block, try cache block, extra paranthesis there which are not good according to the oracle conventions, basically it detects the mistakes nd display 
on the dashboard and also it will be sent to developer slack channel using slack integration in the plugin 
3) code coverage
4) junit testing - junit will generate the report and then we will publish the report on each and every businesscase 
5) building the artifact by using maven clean install to put the artifact in .m2 folder
6) Will push the artifact into Nexus artifatory
7) we will call Ansible playbook to deploy the application on Linux server
8) email notifications 

3) How you are going to validating the configuration was correct or application deployment was successful?
 
  YEs, we have some integration test scripts which we run on post build actions but that is only for crtitical micro services and for normal micro services, we will have a rescue block in the ansible which will just rescue the deployment failed lets say ansible
  was not able to connect, it will print a message on the console and will give the exception in stack trays that way we will know that deployment is fail, something wrong with deployment, will exit the jenkins job status code as non-zero and pipeline will mark as failure
  we will get the notifications as part of the jenkins notification system but for non-prod envs, we are not getting the alerts because unnecessary every 2-3 hrs will get notifications as people are deploying it very frequently, so we have disabled in non-prod envs.
  
4) what was the greatest mistake you did in office and how did you manage?

 SO i think one of the greatest mistake in the job was database manually editing the security group rules for one of the application and inside that i was added some manual error which caused the entire production was down for 10 seconds and immediately rolled it back
 and I actually honestly went to my manager and told him that this is what caused the issue and got the warning back from my manager and at the sametime, my manager appreciated my honesty because no one would have actually known if I would have not told to him.
 
 


2) what is hook , how do you configure

	install github pluggin, and go to manage Jenkins – configure system – add github server – in advanced button – addition section – click managed addition github actions – set credentials with to get the token – add GIThub server – set the token and save

	go to project and under configrure – Build trigger select ‘build when a change is pushed to git ‘ and save

	in Github : 

	settings – webhooks and services – add service – Jenkins – github pluggin – and set url “ http://Jenkins ip/github-webhook” 

	steps in pipeline
	settings required :

3) when you create the new job – select as Pipeline

	1. Configure Maven in Jenkins  - manage Jenkins – configure system – add maven binary location
	2. Running the Maven Build from Jenkins 
	3. Analyzing the Test Report from Jenkins

	we work closely with dev and service team and once the code is pushed into git hub repo , 
	we work on creating the jobs in Jenkins .  
	so for the Jenkins pipeline scripts which pulls the lates version, which does a compilation/package and does a docker image if everything goes well that docker image is pushed to docker hub were they are going to authoendite docker hub using jenkins pipepile code and finally deploy the container to  a dev environmrnt . 

	and we write the pipeline scripts to we pull the docker image from the docker hub and runs it on to the dev envi

	email notification : 

	manage jenkins - configure system – email notification – SMTP server ; give email and pwd , port number, check SSL, 

	you can setup as part of post build	

	Junit report : 

	Advanced project options select “ Use costome work space “  provide the path of the :/W drive
	And the in Post build – generate Junit test results – give the path of the folder where you want to generate the reports “ reports/*.xml

4) Mention what are the commands you can use to start Jenkins manually?
	For this answer I will suggest you to go with the below mentioned flow:

	To start Jenkins manually open Console/Command line, then go to your Jenkins installation directory. Over there you can use the below commands:
	To start Jenkins: jenkins.exe start
	To stop Jenkins: jenkins.exe stop
	To restart Jenkins: jenkins.exe restart

5) Explain how to create a backup and copy files in Jenkins?

	To create a backup all you need to do is to periodically back up your JENKINS_HOME directory. This contains all of your build jobs configurations, your slave node configurations, and your build history. 
	To create a back-up of your Jenkins setup, just copy this directory. You can also copy a job directory to clone or replicate a job or rename the directory.

6) How will you secure Jenkins?

	The way I secure Jenkins is mentioned below, if you have any other way to do it than mention that:
	•	Ensure global security is on.
	•	Ensure that Jenkins is integrated with my company’s user directory with appropriate plugin.
	•	Ensure that matrix/Project matrix is enabled to fine tune access.
	•	Automate the process of setting rights/privileges in Jenkins with custom version controlled script.
	•	Limit physical access to Jenkins data/folders.
	•	Periodically run security audits on same.

7) What you do when you see a broken build for your project in Jenkins?
	There can be multiple answers to this question I will approach this task in the following way:
	I will open the console output for the broken build and try to see if any file changes were missed. If I am unable to find the issue that way, then I will clean and update my local workspace to replicate the problem on my local and try 

8) Explain how you can move or copy Jenkins from one server to another?
	I will approach this task by copying the jobs directory from the old server to the new one. There are multiple ways to do that, I have mentioned it below:	

	You can:
	•	Move a job from one installation of Jenkins to another by simply copying the corresponding job directory.
	•	Make a copy of an existing job by making a clone of a job directory by a different name.
	•	Rename an existing job by renaming a directory. Note that if you change a job name you will need to change any other job that tries to call the renamed job.


9) Explain how you can deploy a custom build of a core plugin?
	Below are the steps to deploy a custom build of a core plugin:
	•	Stop Jenkins.
	•	Copy the custom HPI to $Jenkins_Home/plugins.
	•	Delete the previously expanded plugin directory.
	•	Make an empty file called <plugin>.hpi.pinned.
	•	Start Jenkins.

10) Explain how you can set up Jenkins job?
	My approach to this answer will be to first mention how to create Jenkins job.
	Go to Jenkins top page, select “New Job”, then choose “Build a free-style software project”.
	Now you can tell the elements of this freestyle job:
	•	Optional SCM, such as CVS or Subversion where your source code resides.
	•	Optional triggers to control when Jenkins will perform builds.
	•	Some sort of build script that performs the build (ant, maven, shell script, batch file, etc.) where the real work happens.
	•	Optional steps to collect information out of the build, such as archiving the artifacts and/or recording javadoc and test results.
	•	Optional steps to notify other people/systems with the build result, such as sending e-mails, IMs, updating issue tracker, etc..

11) What are the two components Jenkins is mainly integrated with?
	According to me Jenkins is mainly integrated with the following:
	•	Version Control system like GIT,SVN.
	•	Build tools like Apache Maven.


------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Jenkins scripts:

1) Upload the artifactory to S3 :

Detailed steps:

Install Pipeline AWS Plugin. Go to Manage Jenkins -> Manage Plugins -> Available tab -> Filter by 'Pipeline AWS'. Install the plugin.

Add Credentials as per your environment. Example here:

Jenkins > Credentials > System > Global credentials (unrestricted) -> Add

Kind = AWS Credentials and add your AWS credentials

Note the ID

Then in your Pipeline project (Similar to the code I use)

node {

    stage('Upload') {

        dir('path/to/your/project/workspace'){

            pwd(); //Log current directory

            withAWS(region:'yourS3Region',credentials:'yourIDfromStep2') {

                 def identity=awsIdentity();//Log AWS credentials

                // Upload files from working directory 'dist' in your project workspace
                s3Upload(bucket:"yourBucketName", workingDir:'dist', includePathPattern:'**/*');
            }

        };
    }
}


2) Jenkins - Docker Pipeline:

Jenkinsfile (Declarative Pipeline)
pipeline {
    agent { dockerfile true }
    stages {
        stage('Back-end') {
            agent {
                docker { image 'maven:3-alpine' }
            }
            steps {
                sh 'mvn --version'
            }
        }
        stage('Front-end') {
            agent {
                docker { image 'node:7-alpine' }
            }
            steps {
                sh 'node --version'
            }
        }
    }
}


3) Sample Syntax Generated Pipeline:

node{
	stage('Git Checkout'){
		git 'https://github.com/javahometech/my-app'  
	 }
	stage('Maven Package'){
		sh 'mvn clean package'
		sh 'mv target/myweb*.war target/myweb.war'
	 }
	
	stage('Build Docker Imager'){
	sh 'docker build -t kammana/myweb:0.0.1 .'
	 }
	
	stage('Push to Docker Hub'){
	
		withCredentials([string(credentialsId: 'github-pwd', variable: 'dockerHubPwd')]) {
	sh "docker login -u kammana -p ${dockerHubPwd}"
	     }
		sh 'docker push kammana/myweb:0.0.1'
	 }
	stage('Remove Previous Container'){
		try{
			defdockerRm = 'dockerrm -f myweb'
			sshagent(['docker-dev']) {
				sh "ssh -o StrictHostKeyChecking=no ec2-user@172.31.17.196 ${dockerRm}"
			}
		}catch(error){
			//  do nothing if there is an exception
		}
	 }
	stage('Deploy to Dev Environment'){
	defdockerRun = 'docker run -d -p 8080:8080 --name mywebkammana/myweb:0.0.1 '
	sshagent(['docker-dev']) {
	sh "ssh -o StrictHostKeyChecking=no ec2-user@172.31.17.196 ${dockerRun}"
	   }
	
	 }
	}
	
4) Jenkins pipeline script to call Ansible script:
stage('Deploy to test'){
    steps {
        dir('deployment'){ //do this in the deployment directory!
            echo 'Deploying to test'
            sh 'ansible-playbook -i dev-servers site.yml'
        }
    }
}

5) Jenkins pipeline script for Nexus:

stage('Publish') {
     nexusPublisher nexusInstanceId: 'localNexus', nexusRepositoryId: 'releases', packages: [[$class: 'MavenPackage', mavenAssetList: [[classifier: '', extension: '', filePath: 'war/target/jenkins.war']], mavenCoordinate: [artifactId: 'jenkins-war', groupId: 'org.jenkins-ci.main', packaging: 'war', version:'2.23']]]
   }
}

stage("publish to nexus") {
            steps {
                script {
                    // Read POM xml file using 'readMavenPom' step , this step 'readMavenPom' is included in: https://plugins.jenkins.io/pipeline-utility-steps
                    pom = readMavenPom file: "pom.xml";
                    // Find built artifact under target folder
                    filesByGlob = findFiles(glob: "target/*.${pom.packaging}");
                    // Print some info from the artifact found
                    echo "${filesByGlob[0].name} ${filesByGlob[0].path} ${filesByGlob[0].directory} ${filesByGlob[0].length} ${filesByGlob[0].lastModified}"
                    // Extract the path from the File found
                    artifactPath = filesByGlob[0].path;
                    // Assign to a boolean response verifying If the artifact name exists
                    artifactExists = fileExists artifactPath;
                    if(artifactExists) {
                        echo "*** File: ${artifactPath}, group: ${pom.groupId}, packaging: ${pom.packaging}, version ${pom.version}";
                        nexusArtifactUploader(
                            nexusVersion: NEXUS_VERSION,
                            protocol: NEXUS_PROTOCOL,
                            nexusUrl: NEXUS_URL,
                            groupId: pom.groupId,
                            version: pom.version,
                            repository: NEXUS_REPOSITORY,
                            credentialsId: NEXUS_CREDENTIAL_ID,
                            artifacts: [
                                // Artifact generated such as .jar, .ear and .war files.
                                [artifactId: pom.artifactId,
                                classifier: '',
                                file: artifactPath,
                                type: pom.packaging],
                                // Lets upload the pom.xml file for additional information for Transitive dependencies
                                [artifactId: pom.artifactId,
                                classifier: '',
                                file: "pom.xml",
                                type: "pom"]
                            ]
                        );
                    } else {
                        error "*** File: ${artifactPath}, could not be found";
                    }


6) 


